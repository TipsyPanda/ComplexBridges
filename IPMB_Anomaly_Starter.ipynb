{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TipsyPanda/ComplexBridges/blob/main/IPMB_Anomaly_Starter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b81a8818",
      "metadata": {
        "id": "b81a8818"
      },
      "source": [
        "# IPMB – ML Anomaly Detection Starter Notebook\n",
        "*Generated on 2025-10-13 13:12:05*\n",
        "\n",
        "This notebook covers:\n",
        "1. Data loading & basic EDA\n",
        "2. Rolling-window feature engineering\n",
        "3. Unsupervised anomaly detection (Isolation Forest)\n",
        "4. Threshold calibration & evaluation (time-aware)\n",
        "5. Minimal, stream-friendly scoring loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79317bfc",
      "metadata": {
        "id": "79317bfc"
      },
      "source": [
        "## 1) Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "36f4f5b2",
      "metadata": {
        "id": "36f4f5b2",
        "outputId": "07c9fa5a-7663-409c-cd00-e9ed8161a5a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Install (if running elsewhere) and imports\n",
        "# %pip install pandas numpy scikit-learn matplotlib scipy\n",
        "\n",
        "import os\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Matplotlib defaults (no explicit colors)\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 4)\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# Paths\n",
        "DATA_PATH = \"/content/drive/MyDrive/ComplexSystemDesign/Data/\"  # change if needed"
      ]
    },

  {
   "cell_type": "markdown",
   "id": "84c08c46",
   "metadata": {},
   "source": [
    "## 2) Load with **DatetimeIndex**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf41ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_df_with_datetimeindex(path: str, time_col: Optional[str] = \"timestamp\"):\n",
    "    \"\"\"\n",
    "    Load CSV or Pickle and ensure a DatetimeIndex.\n",
    "    Priority:\n",
    "      1) If already DatetimeIndex -> return as is\n",
    "      2) Else, if `time_col` exists -> parse and set as index\n",
    "      3) Else, try to infer a datetime-like index name\n",
    "    \"\"\"\n",
    "    if path.lower().endswith(\".pkl\") or path.lower().endswith(\".pickle\"):\n",
    "        df = pd.read_pickle(path)\n",
    "    else:\n",
    "        df = pd.read_csv(path)\n",
    "    # 1) already a DatetimeIndex\n",
    "    if isinstance(df.index, pd.DatetimeIndex):\n",
    "        return df.sort_index()\n",
    "    # 2) has a time column to set index\n",
    "    if time_col in df.columns:\n",
    "        df[time_col] = pd.to_datetime(df[time_col], errors='coerce')\n",
    "        df = df.dropna(subset=[time_col]).set_index(time_col).sort_index()\n",
    "        return df\n",
    "    # 3) try to coerce current index\n",
    "    try:\n",
    "        idx = pd.to_datetime(df.index, errors='raise')\n",
    "        df.index = idx\n",
    "        return df.sort_index()\n",
    "    except Exception:\n",
    "        raise ValueError(\"No DatetimeIndex and no time column found. Provide a 'timestamp' column or a pickle with a DatetimeIndex.\")\n",
    "\n",
    "df = load_df_with_datetimeindex(DATA_PATH, time_col=\"timestamp\")\n",
    "print(type(df.index), df.index.min(), \"→\", df.index.max())\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396bce55",
   "metadata": {},
   "source": [
    "## 3) Select a single stream for modeling (per `sensor_id`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645827b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pick the first available sensor_id within the first sensor_type (customize as needed)\n",
    "first_type = df['sensor_type'].dropna().unique()[0]\n",
    "first_sensor = df.loc[df['sensor_type']==first_type, 'sensor_id'].dropna().unique()[0]\n",
    "\n",
    "sub = df[(df['sensor_type']==first_type) & (df['sensor_id']==first_sensor)].copy()\n",
    "sub = sub.sort_index()\n",
    "print(\"Working stream:\", first_type, first_sensor, \"rows:\", len(sub))\n",
    "\n",
    "# Quick raw plot\n",
    "fig = plt.figure()\n",
    "plt.plot(sub.index, sub['value'])\n",
    "plt.title(f\"Raw values – {first_sensor} ({first_type})\")\n",
    "plt.xlabel(\"time\"); plt.ylabel(\"value\")\n",
    "plt.show()\n",
    "\n",
    "# Optional: overlay rule anomalies as vertical lines (if present)\n",
    "if 'anomaly' in sub.columns:\n",
    "    fig = plt.figure()\n",
    "    plt.plot(sub.index, sub['value'])\n",
    "    t_anom = sub.index[sub['anomaly']==1]\n",
    "    for t in t_anom:\n",
    "        plt.axvline(t, linestyle='--', linewidth=0.8)\n",
    "    plt.title(f\"Rule anomalies overlay – {first_sensor}\")\n",
    "    plt.xlabel(\"time\"); plt.ylabel(\"value\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ca4a69",
   "metadata": {},
   "source": [
    "## 4) Rolling-window feature engineering (uses index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85df832",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infer_base_freq(idx: pd.DatetimeIndex) -> str:\n",
    "    \"\"\"Infer a base frequency string from a DatetimeIndex.\"\"\"\n",
    "    # Try pandas inference first\n",
    "    guessed = pd.infer_freq(idx)\n",
    "    if guessed is not None:\n",
    "        return guessed\n",
    "    # Fallback to median delta in milliseconds\n",
    "    deltas = idx.to_series().diff().dropna().dt.total_seconds()\n",
    "    if len(deltas) == 0:\n",
    "        return \"1S\"\n",
    "    ms = int(np.median(deltas) * 1000)\n",
    "    ms = max(ms, 1)  # at least 1ms\n",
    "    return f\"{ms}L\"  # 'L' = milliseconds\n",
    "\n",
    "def make_rolling_features_index(ts: pd.DataFrame, window: str = '30s', step: str = '15s'):\n",
    "    \"\"\"\n",
    "    Build rolling-window features assuming ts.index is a DatetimeIndex.\n",
    "    Keeps time as the index; returns a DataFrame with 't_center' as a datetime column.\n",
    "    \"\"\"\n",
    "    if not isinstance(ts.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"Expected a DatetimeIndex\")\n",
    "    ts = ts.sort_index()\n",
    "\n",
    "    base_freq = infer_base_freq(ts.index)\n",
    "    # Resample to fixed grid, forward-fill short gaps\n",
    "    ts = ts.resample(base_freq).ffill()\n",
    "\n",
    "    start, end = ts.index.min(), ts.index.max()\n",
    "    out = []\n",
    "    cur = start\n",
    "    w = pd.to_timedelta(window)\n",
    "    s = pd.to_timedelta(step)\n",
    "\n",
    "    while cur + w <= end:\n",
    "        win = ts.loc[cur:cur+w]\n",
    "        if len(win) < 3:\n",
    "            cur += s\n",
    "            continue\n",
    "\n",
    "        v = win['value'].values\n",
    "        mean = float(np.mean(v))\n",
    "        std = float(np.std(v, ddof=1)) if len(v) > 1 else 0.0\n",
    "        rms = float(np.sqrt(np.mean(v**2)))\n",
    "        p2p = float(np.max(v) - np.min(v))\n",
    "        skew = float(pd.Series(v).skew()) if len(v) > 2 else 0.0\n",
    "        kurt = float(pd.Series(v).kurtosis()) if len(v) > 3 else 0.0\n",
    "        x = np.arange(len(v))\n",
    "        slope = float(np.polyfit(x, v, 1)[0]) if len(v) > 1 else 0.0\n",
    "        dv = np.diff(v)\n",
    "        adiff_mean = float(np.mean(np.abs(dv))) if len(dv) else 0.0\n",
    "\n",
    "        ctx = {}\n",
    "        if 'traffic_load_proxy' in win.columns:\n",
    "            tl = win['traffic_load_proxy'].values\n",
    "            ctx['ctx_tl_mean'] = float(np.mean(tl))\n",
    "            ctx['ctx_tl_std']  = float(np.std(tl, ddof=1)) if len(tl)>1 else 0.0\n",
    "        if 'rule_threshold' in win.columns:\n",
    "            ctx['ctx_rule_thr'] = float(np.median(win['rule_threshold']))\n",
    "\n",
    "        label = None\n",
    "        if 'anomaly' in win.columns:\n",
    "            label = int((win['anomaly'] == 1).any())\n",
    "\n",
    "        t_center = cur + w/2\n",
    "        row = {\n",
    "            't_center': t_center,\n",
    "            'f_mean': mean, 'f_std': std, 'f_rms': rms, 'f_p2p': p2p,\n",
    "            'f_skew': skew, 'f_kurt': kurt, 'f_slope': slope, 'f_adiff_mean': adiff_mean,\n",
    "            **ctx\n",
    "        }\n",
    "        if label is not None:\n",
    "            row['label_rule'] = label\n",
    "        out.append(row)\n",
    "\n",
    "        cur += s\n",
    "\n",
    "    feats = pd.DataFrame(out).sort_values('t_center').reset_index(drop=True)\n",
    "    return feats\n",
    "\n",
    "feats = make_rolling_features_index(\n",
    "    sub[['value','traffic_load_proxy','rule_threshold','anomaly']].copy(),\n",
    "    window='30s', step='15s'\n",
    ")\n",
    "print(feats.shape)\n",
    "feats.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29442f9",
   "metadata": {},
   "source": [
    "## 5) Temporal split and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223b563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cut = int(len(feats) * 0.7)\n",
    "train = feats.iloc[:cut].copy()\n",
    "test  = feats.iloc[cut:].copy()\n",
    "\n",
    "feature_cols = [c for c in feats.columns if c.startswith('f_') or c.startswith('ctx_')]\n",
    "label_col = 'label_rule' if 'label_rule' in feats.columns else None\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "Xs_tr = scaler.fit_transform(train[feature_cols])\n",
    "Xs_te = scaler.transform(test[feature_cols])\n",
    "\n",
    "import joblib\n",
    "joblib.dump(scaler, os.path.join(ARTIFACT_DIR, \"scaler.joblib\"))\n",
    "print(\"Saved:\", os.path.join(ARTIFACT_DIR, \"scaler.joblib\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0bd56a",
   "metadata": {},
   "source": [
    "## 6) Isolation Forest (unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454140d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,\n",
    "    contamination='auto',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "iso.fit(Xs_tr)\n",
    "\n",
    "score_tr = iso.decision_function(Xs_tr)\n",
    "score_te = iso.decision_function(Xs_te)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(iso, os.path.join(ARTIFACT_DIR, \"isoforest.pkl\"))\n",
    "print(\"Saved:\", os.path.join(ARTIFACT_DIR, \"isoforest.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de8890",
   "metadata": {},
   "source": [
    "## 7) Threshold calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74556b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np, json\n",
    "\n",
    "def pick_threshold(scores, quantile=0.005):\n",
    "    return float(np.quantile(scores, quantile))\n",
    "\n",
    "thr = pick_threshold(score_tr, quantile=0.005)\n",
    "print(\"Chosen threshold:\", thr)\n",
    "\n",
    "with open(os.path.join(ARTIFACT_DIR, \"threshold.json\"), \"w\") as f:\n",
    "    json.dump({\"score_threshold\": thr}, f)\n",
    "print(\"Saved:\", os.path.join(ARTIFACT_DIR, \"threshold.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c754c088",
   "metadata": {},
   "source": [
    "## 8) Evaluation & visuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3d28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support, average_precision_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "alerts_te = (score_te < thr).astype(int)\n",
    "\n",
    "if label_col is not None and label_col in test.columns:\n",
    "    y_true = test[label_col].values\n",
    "    anomaly_score_te = -score_te\n",
    "    ap = average_precision_score(y_true, anomaly_score_te)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_true, alerts_te, average='binary', zero_division=0)\n",
    "    print(f\"AP: {ap:.3f}  Precision: {p:.3f}  Recall: {r:.3f}  F1: {f1:.3f}\")\n",
    "else:\n",
    "    print(\"No labels available; showing score plots only.\")\n",
    "\n",
    "# Score timeline\n",
    "fig = plt.figure()\n",
    "plt.plot(test['t_center'], score_te)\n",
    "plt.axhline(thr, linestyle='--')\n",
    "plt.title(\"IsolationForest score (higher=more normal)\")\n",
    "plt.xlabel(\"time\"); plt.ylabel(\"score\")\n",
    "plt.show()\n",
    "\n",
    "# Alerts (binary)\n",
    "fig = plt.figure()\n",
    "plt.plot(test['t_center'], alerts_te, drawstyle='steps-post')\n",
    "plt.title(\"Alerts (test)\")\n",
    "plt.xlabel(\"time\"); plt.ylabel(\"alert\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1054e91",
   "metadata": {},
   "source": [
    "## 9) Mini scoring loop (DatetimeIndex pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1493a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "events = []\n",
    "for t, s, a in zip(test['t_center'], score_te, (score_te < thr).astype(int)):\n",
    "    if a == 1:\n",
    "        events.append({\"t\": str(t), \"event\": \"ALERT\", \"score\": float(s)})\n",
    "len(events), events[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12cf470",
   "metadata": {},
   "source": [
    "## 10) Notes & next steps\n",
    "- Resampling is driven by the DatetimeIndex (no `timestamp` column).\n",
    "- Extend features with FFT band powers for vibration streams.\n",
    "- Consider per-sensor models for tighter boundaries.\n",
    "- Add drift monitoring with rolling median/MAD of scores.\n",
    "- Wire artifacts into a Streamlit dashboard.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
